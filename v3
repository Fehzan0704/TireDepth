import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import timm  # Using timm for easier model adjustments

model_name = "single_angle_model_v15"
num_epochs = 100
batch_size = 16
learning_rate = 0.0001

# Normalize transformation based on typical ImageNet means and stds
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

# Enhanced data augmentation
augmentation = transforms.Compose([
    transforms.Resize((1024, 1024)),
    transforms.ToTensor(),
    normalize
])

class TireDataset(Dataset):
    def __init__(self, image_paths, depths, transform=None):
        self.image_paths = image_paths
        self.depths = depths
        self.transform = transform
        # Validate the existence of images and store only valid entries
        self.valid_data = [(path, depth) for path, depth in zip(image_paths, depths) if os.path.exists(path)]

    def __len__(self):
        return len(self.valid_data)

    def __getitem__(self, idx):
        image_path, depth = self.valid_data[idx]
        image = Image.open(image_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor([depth], dtype=torch.float)

# Path to dataset and excel file
dataset_folder = '/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Dataset/Single angle - training_validation'
excel_file = '/content/drive/MyDrive/Bachelorprosjekt - Continental/Conti - Final folder/Datasett.xlsx'

# Load dataset from Excel file
df = pd.read_excel(os.path.join(dataset_folder, excel_file))

# Split dataset into training and validation sets
train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)

# Construct full paths to the image files
train_df['FullImagePath'] = train_df['Bilde'].apply(lambda x: os.path.join(dataset_folder, x))
val_df['FullImagePath'] = val_df['Bilde'].apply(lambda x: os.path.join(dataset_folder, x))

# Create dataset instances using the full image paths
train_dataset = TireDataset(
    train_df['FullImagePath'].tolist(),
    train_df['Dybde (mm)'].tolist(),
    transform=augmentation
)

val_dataset = TireDataset(
    val_df['FullImagePath'].tolist(),
    val_df['Dybde (mm)'].tolist(),
    transform=augmentation
)

# Create DataLoader instances
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=int(batch_size / 2), shuffle=False)

# Define Model using timm
class SimpleDepthEstimator(nn.Module):
    def __init__(self):
        super(SimpleDepthEstimator, self).__init__()
        self.features = timm.create_model('resnet34', pretrained=True, drop_rate=0.5)
        self.features.fc = nn.Identity()
        self.depth_layers = nn.Sequential(
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, 1)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.depth_layers(x)
        return x

model = SimpleDepthEstimator()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Define Loss and Optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=10, cooldown=10)

train_losses = []
val_losses = []
predicted_depths = []
actual_depths = []

# Training and Validation Loop
for epoch in range(num_epochs):
    model.train()
    train_loss_accum = 0
    for batch_idx, (images, depths) in enumerate(train_loader):
        images, depths = images.to(device), depths.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, depths)
        loss.backward()
        optimizer.step()
        train_loss_accum += loss.item() * images.size(0)  # Adjust for variable batch sizes

        if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == 1:
            print(f'Epoch {epoch+1}, Batch {batch_idx+1}/{len(train_loader)}, Train Loss: {loss.item():.4f}')

    average_train_loss = train_loss_accum / len(train_dataset)
    train_losses.append(average_train_loss)
    print(f'Epoch {epoch+1}, Average Train Loss: {average_train_loss:.4f}')

    model.eval()
    val_loss_accum = 0
    for batch_idx, (images, depths) in enumerate(val_loader):
        images, depths = images.to(device), depths.to(device)
        with torch.no_grad():
            outputs = model(images)
            loss = criterion(outputs, depths)
        val_loss_accum += loss.item() * images.size(0)

        if batch_idx == 0:
            # Generate saliency map
            images.requires_grad_()
            outputs = model(images)
            outputs.backward(torch.ones_like(outputs))
            saliency, _ = torch.max(images.grad.data.abs(), dim=1)
            saliency = saliency[0].cpu().numpy()

            plt.figure(figsize=(15, 4))

            plt.subplot(1, 3, 1)
            plt.imshow(images[0].cpu().detach().permute(1, 2, 0))
            plt.title('Original Image')

            plt.subplot(1, 3, 2)
            plt.imshow(saliency, cmap='hot')
            plt.title('Saliency Map')

            plt.subplot(1, 3, 3)
            plt.imshow(images[0].cpu().detach().permute(1, 2, 0))
            plt.imshow(saliency, cmap='hot', alpha=0.4)
            plt.title('Saliency Map Overlaid')

            plt.show()

        predicted_depths.append(outputs.detach().cpu().numpy())
        actual_depths.append(depths.detach().cpu().numpy())

        if (batch_idx + 1) % 3 == 0 or (batch_idx + 1) == 1:
            print(f'Epoch {epoch+1}, Validation Batch {batch_idx+1}/{len(val_loader)}, Validation Loss: {loss.item():.4f}')

    average_val_loss = val_loss_accum / len(val_dataset)
    val_losses.append(average_val_loss)
    print(f'Epoch {epoch+1}, Average Validation Loss: {average_val_loss:.4f}')
    scheduler.step(average_val_loss)

# Save the model
model_save_path = f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/{model_name}/{model_name}_final.pth'
torch.save(model.state_dict(), model_save_path)

# Save losses and predictions to CSV
results_df = pd.DataFrame({
    'Train Loss': train_losses,
    'Validation Loss': val_losses,
    'Predicted Depth': [p[0] for p in predicted_depths],
    'Actual Depth': [a[0] for a in actual_depths]
})
results_csv_path = f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/{model_name}/{model_name}_results.csv'
results_df.to_csv(results_csv_path, index=False)
