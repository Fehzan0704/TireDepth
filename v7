import os
import pandas as pd
from sklearn.model_selection import train_test_split
import torch
import torchvision
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torchvision.models import ResNet34_Weights
from torch.optim.lr_scheduler import ReduceLROnPlateau
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from captum.attr import GuidedGradCam
from captum.attr import visualization as viz
import warnings

# Filter Captum's UserWarning
warnings.filterwarnings("ignore", category=UserWarning, module="captum")

# Paths to dataset and labels
dataset_path = r'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Dataset/Single angle - FULL'
labels_path = r'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Dataset/Datasett.xlsx'

batch_size = 32
num_epochs = 100
learning_rate = 0.0005
version = 6
patience = 5 # Epochs before stopping to prevent overfitting

figure_size = (10, 5) # Size of all generated plots
gradcam_frequency = 5 # How many epochs between the gradcam visualization
save_frequency = 4 # How often an epoch should be saved (first and best will always be saved)
resolution = 1024 # Image size in pixel (images are square so width and height is same)

# Load labels from Excel file
labels_df = pd.read_excel(labels_path)

# Function to get label for a specific image
def get_label(image_name):
    label = labels_df[labels_df['Bilde'] == f"{image_name}.jpg"]['Dybde (mm)'].values
    if len(label) > 0:
        return label[0]
    else:
        return None

# List all image files in dataset directory
image_files = os.listdir(dataset_path)

# Extract image names without extensions
image_names = [os.path.splitext(file)[0] for file in image_files]

# Split dataset into train, validation, and test sets
train_names, temp_names = train_test_split(image_names, test_size=0.3, random_state=7)
val_names, test_names = train_test_split(temp_names, test_size=0.5, random_state=7) # 15% validation, 15% test

# Create dictionaries to store labels
train_labels = {name: get_label(name) for name in train_names if get_label(name) is not None}
val_labels = {name: get_label(name) for name in val_names if get_label(name) is not None}
test_labels = {name: get_label(name) for name in test_names if get_label(name) is not None}

# Log missing labels
missing_labels = [name for name in train_names + val_names + test_names if get_label(name) is None]
if missing_labels:
    print(f"Missing labels for {len(missing_labels)} images\n")
else:
    print("All labels were found\n")

total_images = (len(image_files) - len(missing_labels))

print(f"Total dataset size: {total_images}\n")
print(f"Training: {len(train_labels)}")
print(f"Validation: {len(val_labels)}")
print(f"Test: {len(test_labels)}\n")


class CustomDataset(Dataset):
    def __init__(self, image_names, labels, dataset_path, transform=None):
        self.image_names = image_names
        self.labels = labels
        self.dataset_path = dataset_path
        self.transform = transform

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        image_name = self.image_names[idx]
        image_path = os.path.join(self.dataset_path, f"{image_name}.jpg")
        image = Image.open(image_path).convert("RGB")

        # Get the dimensions of the image
        width, height = image.size

        # Calculate the cropping coordinates for the middle 60% of the width
        left = int(0.2 * width)
        right = int(0.8 * width)
        upper = 0
        lower = height

        # Crop the image
        image = image.crop((left, upper, right, lower))

        if self.transform:
            image = self.transform(image)

        label = self.labels[image_name]
        return image, label

# Define transformations for data preprocessing
transform = transforms.Compose([
    transforms.Resize((resolution, int(resolution * 0.6))),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create custom datasets
train_dataset = CustomDataset(list(train_labels.keys()), train_labels, dataset_path, transform=transform)
val_dataset = CustomDataset(list(val_labels.keys()), val_labels, dataset_path, transform=transform)
test_dataset = CustomDataset(list(test_labels.keys()), test_labels, dataset_path, transform=transform)

# Define data loaders
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)
test_loader = DataLoader(test_dataset, batch_size=batch_size)

# Check if GPU is available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Currently utilizing: {device}\n")

# Define CNN model architecture using ResNet as feature extractor
class CNNResNet(nn.Module):
    def __init__(self):
        super(CNNResNet, self).__init__()
        resnet = torchvision.models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)
        # Extract features from ResNet
        self.resnet_features = nn.Sequential(*list(resnet.children())[:-1])
        # Add additional layers for regression
        self.fc = nn.Linear(512, 1)  # ResNet34's output channels is 512

    def forward(self, x):
        # Extract features using ResNet
        features = self.resnet_features(x)
        # Flatten the features
        features = torch.flatten(features, 1)
        # Apply additional layers for regression
        output = self.fc(features)
        return output

# Initialize model
model = CNNResNet()

# Move model to device
model = model.to(device)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Initialize lists to store training and validation loss values and average error
train_losses = []
val_losses = []
avg_train_errors = []
avg_val_errors = []
val_errors = []
val_percentage_errors = []
patience_counter = 0
best_val_loss = float('inf')

for epoch in range(num_epochs):
    model.train()
    epoch_train_loss = 0.0
    train_errors = []

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.float().to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs.squeeze(), labels)
        loss.backward()
        optimizer.step()
        epoch_train_loss += loss.item() * inputs.size(0)
        train_errors.extend((labels - outputs.squeeze()).detach().cpu().numpy())

    epoch_train_loss /= len(train_loader.dataset)
    avg_train_error = np.mean(np.abs(train_errors))
    train_losses.append(epoch_train_loss)
    avg_train_errors.append(avg_train_error)

    # Validation step
    model.eval()
    epoch_val_loss = 0.0
    val_errors = []
    val_percentage_errors = []

    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(device), labels.float().to(device)
            outputs = model(inputs)
            loss = criterion(outputs.squeeze(), labels)
            epoch_val_loss += loss.item() * inputs.size(0)
            errors = abs(labels - outputs.squeeze()).cpu().numpy()
            val_errors.extend(errors)

            # Safely calculate percentage errors
            safe_labels = labels.cpu().numpy() + 1e-8  # Avoid division by zero
            percentage_errors = (errors / safe_labels) * 100
            val_percentage_errors.extend(percentage_errors)

    epoch_val_loss /= len(val_loader.dataset)
    avg_val_error = np.mean(val_errors)
    avg_val_percentage_error = np.mean(val_percentage_errors)
    val_losses.append(epoch_val_loss)
    avg_val_errors.append(avg_val_error)

    print(f"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_train_loss:.2f}, Val Loss: {epoch_val_loss:.2f}, Train Error: {avg_train_error:.2f}, Val Error: {avg_val_error:.2f}")

    # Early stopping
    if epoch_val_loss < best_val_loss:
        best_val_loss = epoch_val_loss
        patience_counter = 0
        # Ensure the directory exists before saving the model
        best_model_path = f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/.pth files/Resnet34_v{version}_best.pth'
        os.makedirs(os.path.dirname(best_model_path), exist_ok=True)
        torch.save(model.state_dict(), best_model_path)
    else:
        patience_counter += 1
        if patience_counter >= patience:
            print("Early stopping triggered")
            break

    # Guided Grad-CAM Visualization
    convlayer = list(list(list(list(model.children())[0].children())[-3].children())[-1].children())[-3]
    guided_gc = GuidedGradCam(model, convlayer)

    fig, axs = plt.subplots(2, 8, figsize=(20, 8))  # Adjust size as needed
    for i, ax in enumerate(axs.flat):
        model_input, _ = val_dataset[i]
        model_input = model_input.requires_grad_().to(device).unsqueeze(0)

        attribution = guided_gc.attribute(model_input, target=0)
        attr = np.transpose(attribution.squeeze().cpu().detach().numpy(), (1, 2, 0))
        original_img = np.transpose(model_input.squeeze().cpu().detach().numpy(), (1, 2, 0))

        # Visualize the attribution in the specified subplot
        _, _ = viz.visualize_image_attr(
            attr=attr,
            original_image=original_img,
            method='blended_heat_map',
            sign='absolute_value',
            plt_fig_axis=(fig, ax),
            alpha_overlay=0.5,
            show_colorbar=True,
            use_pyplot=False
        )
        ax.set_xticks([])  # Remove x-axis tick marks
        ax.set_yticks([])  # Remove y-axis tick marks
        ax.axis('off')  # Hide the axes

        gradcam_path = f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/GradCam/epoch_{epoch+1}.png'
        os.makedirs(os.path.dirname(gradcam_path), exist_ok=True)
        plt.savefig(gradcam_path)

    if epoch == 0 or epoch == (num_epochs - 1) or epoch % (gradcam_frequency - 1) == 0:
        plt.show()
        print()

    if epoch == 0 or epoch == (num_epochs - 1) or epoch % (save_frequency - 1) == 0:
        model_save_path = f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/.pth files/Resnet34_epoch_{epoch + 1}.pth'
        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
        torch.save(model.state_dict(), model_save_path)

    plt.close()

# Plotting the training and validation loss graph and average errors
plt.figure(figsize=(figure_size[0] * 1.5, figure_size[1] * 1.5))
plt.subplot(1, 2, 1)
plt.plot(range(1, epoch+2), train_losses, label='Training Loss')
plt.plot(range(1, epoch+2), val_losses, label='Validation Loss')
plt.title('Training and Validation Loss over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.grid(True)
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(range(1, epoch+2), avg_train_errors, label='Average Training Error')
plt.plot(range(1, epoch+2), avg_val_errors, label='Average Validation Error')
plt.title('Average Error over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Average Error')
plt.grid(True)
plt.legend()

plt.savefig(f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/v{version}_LossesPlot.png')
plt.show()
plt.close()
print()

# Evaluation on the test set
model.eval()
test_loss = 0.0
actual_depth = []
predicted_depth = []
signed_residuals = []
percentage_residuals = []  # List to store percentage residuals

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs, labels = inputs.to(device), labels.float().to(device)
        outputs = model(inputs)
        loss = criterion(outputs.squeeze(), labels)
        test_loss += loss.item() * inputs.size(0)
        actual_labels = labels.cpu().numpy()  # Get actual values
        predicted_labels = outputs.squeeze().detach().cpu().numpy()  # Get predicted values
        actual_depth.extend(actual_labels)
        predicted_depth.extend(predicted_labels)

        # Calculate signed residuals
        current_signed_residuals = actual_labels - predicted_labels
        signed_residuals.extend(current_signed_residuals)  # For signed residuals

        # Safely calculate percentage residuals
        safe_labels = actual_labels + 1e-8  # Avoid division by zero
        percentage_residuals.extend((abs(current_signed_residuals) / safe_labels) * 100)

test_loss /= len(test_loader.dataset)
practical_accuracy = np.mean(signed_residuals)  # This can be negative or positive
avg_percentage_residual = np.mean(percentage_residuals)
percentage_accuracy = 100 - avg_percentage_residual
practical_accuracy = - practical_accuracy

# Scatter plot for actual vs predicted depth with diagonal line
plt.figure(figsize=(figure_size))
plt.scatter(actual_depth, predicted_depth, alpha=0.5, label='Data Points')
plt.plot([min(actual_depth), max(actual_depth)], [min(actual_depth), max(actual_depth)], color='red', label='Ideal Fit')
plt.title('Actual vs Predicted Depth (closer to line == better)')
plt.xlabel('Actual Depth (mm)')
plt.ylabel('Predicted Depth (mm)')
plt.legend()
plt.grid(True)
plt.savefig(f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/v{version}_ScatterPlot.png')
plt.show()
plt.close()
print()

# Histogram of residuals
plt.figure(figsize=(figure_size))
plt.hist(signed_residuals, bins=20, alpha=0.7, color='blue', edgecolor='black')
plt.title('Histogram of difference (Actual - Predicted)')
plt.xlabel('Difference (mm)')
plt.ylabel('Frequency')
plt.grid(True)
plt.savefig(f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/v{version}_Histogram.png')
plt.show()
plt.close()
print()

# Print results
print(f'Test Loss: {test_loss:.2f} (lower is better)\n')
print("Testing set analytics")
print(f'Average estimation difference (mm): {practical_accuracy:.2f} mm (positive means overestimate, negative means underestimate)')
print(f'Accuracy (%): {percentage_accuracy:.2f}% (higher is better)\n')

# Prepare DataFrame
loss_data = pd.DataFrame({
    'Epoch': range(1, epoch + 2),
    'Training Loss': train_losses,
    'Validation Loss': val_losses,
    'Average Train Error (mm)': avg_train_errors,
    'Average Validation Error (mm)': avg_val_errors,
    'Validation Error (%)': avg_val_percentage_error,  # List of average percentage errors per epoch for validation
})

excel_path = f'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Generated models/Resnet_v{version}/v{version}_loss_data.xlsx'

loss_data.to_excel(excel_path, index=False)
print(f"Loss data saved to {excel_path}\n")

# Prediction Example
'''test_image_path = r'/content/drive/MyDrive/Bachelorprosjekt - Continental/LAST/Dataset/SA - validation/IMG_2394.jpg'
test_image = Image.open(test_image_path)
test_image = transform(test_image)  # Apply the same transformations
test_image_batch = test_image.unsqueeze(0)

with torch.no_grad():
    depth_prediction = model(test_image_batch.to(device))
    depth_prediction = depth_prediction.item()
    print(f'Predicted depth: {depth_prediction}')'''
